use crate::stream::{
    AudioSamples, DecoderInfo, MediaDecoder, StreamInfo, SubtitlePacket, VideoFrame,
};
#[cfg(feature = "subtitles")]
use crate::subtitle::Subtitle;
use crate::{AudioDevice, NoAudioDevice, format_time};
use anyhow::Result;
use egui::load::SizedTexture;
use egui::text::LayoutJob;
use egui::{
    Align2, Color32, ColorImage, Event, FontId, Image, Key, Rect, Response, Sense, Stroke,
    StrokeKind, TextFormat, TextureHandle, TextureOptions, Ui, Vec2, Widget, pos2, vec2,
};
use log::{info, trace};
use std::fmt::Display;
use std::ops::Add;
use std::sync::Arc;
use std::sync::atomic::{
    AtomicBool, AtomicI8, AtomicI16, AtomicI64, AtomicU8, AtomicU16, Ordering,
};
use std::sync::mpsc::Receiver;
use std::time::{Duration, Instant};

#[cfg(not(feature = "subtitles"))]
struct Subtitle;

/// Generic overlay for player controls
pub trait PlayerOverlay: Send {
    /// Show the overlay
    fn show(&self, ui: &mut Ui, frame_response: &Response, p: &PlaybackInfo) -> PlaybackUpdate;
}

struct NoOverlay;
impl PlayerOverlay for NoOverlay {
    fn show(&self, _ui: &mut Ui, _frame_response: &Response, _p: &PlaybackInfo) -> PlaybackUpdate {
        PlaybackUpdate::default()
    }
}

/// Shared playback state
#[derive(Clone)]
pub struct SharedPlaybackState {
    pub volume: Arc<AtomicU16>,
    pub state: Arc<AtomicU8>,
    pub speed: Arc<AtomicI8>,
    pub mute: Arc<AtomicBool>,
    pub looping: Arc<AtomicBool>,
    pub pts: Arc<AtomicI64>,
}

/// Current state object from the player
#[derive(Debug, Clone)]
pub struct PlaybackInfo {
    pub state: PlayerState,
    pub duration: f32,
    pub elapsed: f32,
    pub volume: f32,
    pub muted: bool,
    pub playback_speed: f32,
    pub looping: bool,
    pub fullscreen: bool,
    pub debug: bool,
}

/// Requested change in player state
#[derive(Debug, Clone, Default)]
pub struct PlaybackUpdate {
    /// Set the player state
    pub set_state: Option<PlayerState>,
    /// Set the playback volume
    pub set_volume: Option<f32>,
    /// Seek to playback position as a percentage of the duration of the media ??
    pub set_seek: Option<f32>,
    /// Set the audio to muted
    pub set_muted: Option<bool>,
    /// Set the playback speed
    pub set_playback_speed: Option<f32>,
    /// Set playback to loop
    pub set_looping: Option<bool>,
    /// Set player fullscreen mode
    pub set_fullscreen: Option<bool>,
    /// Set debug information display
    pub set_debug: Option<bool>,
}

impl PlaybackUpdate {
    /// True if any state changes are requested
    pub fn any(&self) -> bool {
        self.set_state.is_some()
            || self.set_volume.is_some()
            || self.set_seek.is_some()
            || self.set_muted.is_some()
            || self.set_playback_speed.is_some()
            || self.set_looping.is_some()
            || self.set_fullscreen.is_some()
            || self.set_debug.is_some()
    }
}

/// The [`Player`] processes and controls streams of video/audio.
/// This is what you use to show a video file.
/// Initialize once, and use the [`Player::ui`] or [`Player::ui_at()`] functions to show the playback.
pub struct Player {
    overlay: Box<dyn PlayerOverlay>,
    state: SharedPlaybackState,
    debug: bool,

    avg_fps: f32,
    avg_fps_start: Instant,
    last_frame_counter: u64,

    /// The video frame to display
    frame: TextureHandle,
    /// Start presentation time for the current frame
    frame_pts: f64,
    /// End presentation timestamp for the current frame
    frame_pts_end: f64,
    /// Clock time when the frame began
    frame_instant: Instant,

    /// How many frames have been rendered so far
    frame_counter: u64,
    /// Maintain video aspect ratio
    maintain_aspect: bool,
    /// If player should fullscreen
    fullscreen: bool,
    /// If key presses should be handled
    key_binds: bool,

    /// Stream info
    stream_info: Option<DecoderInfo>,

    ctx: egui::Context,
    input_path: String,
    audio: Box<dyn AudioDevice>,
    subtitle: Option<Subtitle>,

    /// Media stream decoder thread
    media_player: MediaDecoder,
    rx_metadata: Receiver<DecoderInfo>,
    rx_video: Receiver<VideoFrame>,
    rx_subtitle: Receiver<SubtitlePacket>,

    /// An error which prevented playback
    error: Option<String>,

    /// Message to show on scree for a short time (usually from keyboard input)
    osd: Option<String>,
    osd_end: Instant,
}

/// The possible states of a [`Player`].
#[derive(PartialEq, Clone, Copy, Debug)]
#[repr(u8)]
#[non_exhaustive]
pub enum PlayerState {
    /// No playback.
    Stopped,
    /// Stream is seeking. Inner bool represents whether the seek is currently in progress.
    Seeking,
    /// Playback is paused.
    Paused,
    /// Playback is ongoing.
    Playing,
}

impl From<u8> for PlayerState {
    fn from(value: u8) -> Self {
        match value {
            0 => PlayerState::Stopped,
            1 => PlayerState::Seeking,
            2 => PlayerState::Paused,
            3 => PlayerState::Playing,
            _ => PlayerState::Stopped,
        }
    }
}

impl Display for PlayerState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            PlayerState::Stopped => write!(f, "Stopped"),
            PlayerState::Seeking => write!(f, "Seeking"),
            PlayerState::Paused => write!(f, "Paused"),
            PlayerState::Playing => write!(f, "Playing"),
        }
    }
}

impl Player {
    /// Store the next image
    fn load_frame(&mut self, frame: VideoFrame) {
        trace!(
            "Loading video frame idx={}, pts={}, dur={}",
            self.frame_counter, frame.pts, frame.duration
        );
        self.frame.set(frame.data, TextureOptions::default());
        self.frame_pts = frame.pts;
        self.frame_pts_end = frame.pts + frame.duration;
        self.frame_counter += 1;
        self.frame_instant = Instant::now();
    }

    fn request_repaint_for_next_frame(&self) {
        let now = Instant::now();
        let frame_duration = self.frame_pts_end - self.frame_pts;
        let next_frame = self
            .frame_instant
            .add(Duration::from_secs_f64(frame_duration));
        if now > next_frame {
            trace!("request repaint now!");
            self.ctx.request_repaint();
        } else {
            let tt_nf = next_frame - now;
            trace!("request repaint for {}ms", tt_nf.as_millis());
            self.ctx.request_repaint_after(tt_nf);
        }
    }

    /// Check if the current frame should be flipped
    fn check_load_frame(&mut self) -> bool {
        if self.state.state.load(Ordering::Relaxed) == PlayerState::Paused as u8 {
            // force frame to start now, while paused
            self.frame_instant = Instant::now();
            return false;
        }

        let now = Instant::now();
        now >= self.frame_end_instant()
    }

    /// Duration of the current frame
    fn frame_duration(&self) -> Duration {
        Duration::from_secs_f64(self.frame_pts_end - self.frame_pts)
    }

    /// Instant when the current frame ends
    fn frame_end_instant(&self) -> Instant {
        self.frame_instant.add(self.frame_duration())
    }

    /// Enable/Disable built-in keybind controls
    pub fn enable_keybinds(&mut self, v: bool) {
        self.key_binds = v;
    }

    /// Handle key input
    fn handle_keys(&mut self, ui: &mut Ui, state: &PlaybackInfo) -> PlaybackUpdate {
        const SEEK_STEP: f32 = 5.0;
        const VOLUME_STEP: f32 = 0.1;
        const SPEED_STEP: f32 = 0.1;

        if !self.key_binds {
            return PlaybackUpdate::default();
        }

        let mut p_ret = PlaybackUpdate::default();
        ui.input(|inputs| {
            for e in &inputs.events {
                match e {
                    Event::Key { key, pressed, .. } if *pressed => match key {
                        Key::Space => {
                            if state.state == PlayerState::Playing {
                                p_ret.set_state.replace(PlayerState::Paused);
                            } else {
                                p_ret.set_state.replace(PlayerState::Playing);
                            }
                        }
                        Key::OpenBracket => {
                            p_ret
                                .set_playback_speed
                                .replace(state.playback_speed - SPEED_STEP);
                        }
                        Key::CloseBracket => {
                            p_ret
                                .set_playback_speed
                                .replace(state.playback_speed + SPEED_STEP);
                        }
                        Key::ArrowRight => {
                            p_ret.set_seek.replace(state.elapsed + SEEK_STEP);
                        }
                        Key::ArrowLeft => {
                            p_ret.set_seek.replace(state.elapsed - SEEK_STEP);
                        }
                        Key::ArrowUp => {
                            p_ret.set_volume.replace(state.volume + VOLUME_STEP);
                        }
                        Key::ArrowDown => {
                            p_ret.set_volume.replace(state.volume - VOLUME_STEP);
                        }
                        Key::F => {
                            p_ret.set_fullscreen.replace(!state.fullscreen);
                        }
                        Key::F1 => {
                            p_ret.set_debug.replace(!state.debug);
                        }
                        _ => {}
                    },
                    _ => {}
                }
            }
        });
        p_ret
    }

    fn process_state(&mut self) {
        let current_state = PlayerState::from(self.state.state.load(Ordering::Relaxed));
        if self.stream_info.is_none()
            && let Ok(md) = self.rx_metadata.try_recv()
        {
            self.stream_info.replace(md);
            if current_state != PlayerState::Playing {
                self.state
                    .state
                    .store(PlayerState::Playing as _, Ordering::Relaxed);
            }
        }

        if current_state == PlayerState::Stopped {
            // nothing to do, playback is stopped
            return;
        }

        //self.media_player.set_target_size(size);
        let duration_since_frame_start = self.frame_instant.elapsed().as_secs_f64();
        let current_pts = self.frame_pts + duration_since_frame_start;
        let current_pts = (current_pts * 1000.0) as _;
        self.state.pts.store(current_pts, Ordering::Relaxed);

        // check if we should load the next video frame
        if !self.check_load_frame() {
            self.request_repaint_for_next_frame();
            return;
        }

        // reset avg fps every 1s
        let n_frames = self.frame_counter - self.last_frame_counter;
        if n_frames >= 30 {
            self.avg_fps = n_frames as f32 / (Instant::now() - self.avg_fps_start).as_secs_f32();
            self.avg_fps_start = Instant::now();
            self.last_frame_counter = self.frame_counter;
        }

        if let Ok(msg) = self.rx_video.recv() {
            self.load_frame(msg);
            // break on video frame
            // once we load the next frame this loop will not call again until
            // this frame is over (pts + duration)
            self.request_repaint_for_next_frame();
            return;
        }

        // if no frames were found just request repaint again
        self.request_repaint_for_next_frame();
    }

    fn generate_frame_image(&self, size: Vec2) -> Image<'_> {
        Image::new(SizedTexture::new(self.frame.id(), size)).sense(Sense::click())
    }

    fn render_frame(&self, ui: &mut Ui) -> Response {
        self.render_frame_at(ui, ui.available_rect_before_wrap())
    }

    /// Exact size of the video frame inside a given [Rect]
    fn video_frame_size(&self, rect: Rect) -> Vec2 {
        if self.maintain_aspect {
            let bv = self.current_video_stream();
            let video_size = bv
                .map(|v| vec2(v.width as f32, v.height as f32))
                .unwrap_or(rect.size());
            let ratio = video_size.x / video_size.y;
            let rect_ratio = rect.width() / rect.height();
            if ratio > rect_ratio {
                let h = rect.width() / ratio;
                vec2(rect.width().floor(), h.floor())
            } else if ratio < rect_ratio {
                let w = rect.height() * ratio;
                vec2(w.floor(), rect.height().floor())
            } else {
                rect.size()
            }
        } else {
            rect.size()
        }
    }

    fn render_frame_at(&self, ui: &mut Ui, rect: Rect) -> Response {
        let video_size = self.video_frame_size(rect);
        ui.painter()
            .rect(rect, 0.0, Color32::BLACK, Stroke::NONE, StrokeKind::Middle);
        ui.put(rect, self.generate_frame_image(video_size))
    }

    fn render_subtitles(&mut self, _ui: &mut Ui) {
        #[cfg(feature = "subtitles")]
        if let Some(s) = self.subtitle.as_ref() {
            let sub_end = s.pts + s.duration;
            if sub_end < self.current_pts() {
                self.subtitle.take();
            } else {
                ui.add(s);
            }
        }
    }

    fn render_debug(&mut self, ui: &mut Ui, frame_response: &Response, p: &PlaybackInfo) {
        let painter = ui.painter();

        const PADDING: f32 = 5.0;
        let vec_padding = vec2(PADDING, PADDING);
        let job = self.debug_inner(frame_response.rect, p);
        let galley = painter.layout_job(job);
        let mut bg_pos = galley
            .rect
            .translate(frame_response.rect.min.to_vec2() + vec_padding);
        bg_pos.max += vec_padding * 2.0;
        painter.rect_filled(bg_pos, PADDING, Color32::from_black_alpha(150));
        painter.galley(bg_pos.min + vec_padding, galley, Color32::PLACEHOLDER);
    }

    fn show_osd(&mut self, msg: &str) {
        self.osd = Some(msg.to_string());
        self.osd_end = Instant::now() + Duration::from_secs(2);
    }

    /// Get the currently playing video stream info
    fn current_video_stream(&self) -> Option<&StreamInfo> {
        if let Some(i) = self.stream_info.as_ref() {
            let v_index = self
                .media_player
                .data
                .selected_video
                .load(Ordering::Relaxed);
            i.streams.iter().find(|s| s.index == v_index as _)
        } else {
            None
        }
    }

    /// Get the currently playing audio stream info
    fn current_audio_stream(&self) -> Option<&StreamInfo> {
        if let Some(i) = self.stream_info.as_ref() {
            let v_index = self
                .media_player
                .data
                .selected_audio
                .load(Ordering::Relaxed);
            i.streams.iter().find(|s| s.index == v_index as _)
        } else {
            None
        }
    }

    /// Get the currently playing subtitle stream info
    fn current_subtitle_stream(&self) -> Option<&StreamInfo> {
        if let Some(i) = self.stream_info.as_ref() {
            let v_index = self
                .media_player
                .data
                .selected_subtitle
                .load(Ordering::Relaxed);
            i.streams.iter().find(|s| s.index == v_index as _)
        } else {
            None
        }
    }

    fn debug_inner(&mut self, frame_response: Rect, p: &PlaybackInfo) -> LayoutJob {
        let font = TextFormat::simple(FontId::monospace(11.), Color32::WHITE);

        let mut layout = LayoutJob::default();
        // layout.append(
        //     &format!(
        //         "sync: v:{:.3}s, a:{:.3}s, a-sync:{:.3}s, buffer: {:.3}s",
        //         v_pts,
        //         a_pts,
        //         a_pts - v_pts,
        //         buffer
        //     ),
        //     0.0,
        //     font.clone(),
        // );

        let video_stream = self.current_video_stream();
        let video_size = self.video_frame_size(frame_response);
        layout.append(
            &format!(
                "\nplayback: {:.2} fps ({:.2}x), volume={:.0}%, resolution={}x{}",
                self.avg_fps,
                self.avg_fps / video_stream.map(|s| s.fps).unwrap_or(1.0),
                100.0 * p.volume,
                video_size.x,
                video_size.y
            ),
            0.0,
            font.clone(),
        );

        if let Some(info) = self.stream_info.as_ref() {
            let bitrate_str = if info.bitrate > 1_000_000 {
                format!("{:.1}M", info.bitrate as f32 / 1_000_000.0)
            } else if info.bitrate > 1_000 {
                format!("{:.1}k", info.bitrate as f32 / 1_000.0)
            } else {
                info.bitrate.to_string()
            };

            layout.append(
                &format!(
                    "\nduration: {}, bitrate: {}",
                    format_time(info.duration),
                    bitrate_str
                ),
                0.0,
                font.clone(),
            );

            fn print_chan(layout: &mut LayoutJob, font: TextFormat, chan: Option<&StreamInfo>) {
                if let Some(c) = chan {
                    layout.append(&format!("\n  {}", c), 0.0, font.clone());
                }
            }
            print_chan(&mut layout, font.clone(), video_stream);
            print_chan(&mut layout, font.clone(), self.current_audio_stream());
            print_chan(&mut layout, font.clone(), self.current_subtitle_stream());
        }

        layout
    }

    /// Create a new [`Player`].
    pub fn new(ctx: &egui::Context, input_path: &str) -> Result<Self> {
        let state = SharedPlaybackState {
            state: Arc::new(AtomicU8::new(PlayerState::Stopped as _)),
            volume: Arc::new(AtomicU16::new(u16::MAX)),
            speed: Arc::new(AtomicI8::new(100)),
            mute: Arc::new(AtomicBool::new(false)),
            looping: Arc::new(AtomicBool::new(false)),
            pts: Arc::new(AtomicI64::new(0)),
        };

        let (media_player, streams) =
            MediaDecoder::new(input_path).expect("Failed to create media playback");

        let audio = Self::open_audio(state.clone(), streams.audio)?;

        let init_size = ctx.available_rect();
        Ok(Self {
            state,
            overlay: Box::new(NoOverlay),
            key_binds: false,
            input_path: input_path.to_string(),
            frame: ctx.load_texture(
                "video_frame",
                ColorImage::filled(
                    [init_size.width() as usize, init_size.height() as usize],
                    Color32::BLACK,
                ),
                Default::default(),
            ),
            frame_instant: Instant::now(),
            frame_pts: 0.0,
            frame_pts_end: 0.0,
            ctx: ctx.clone(),
            audio,
            subtitle: None,
            media_player,
            rx_metadata: streams.metadata,
            rx_video: streams.video,
            debug: false,
            avg_fps: 0.0,
            avg_fps_start: Instant::now(),
            frame_counter: 0,
            last_frame_counter: 0,
            error: None,
            osd: None,
            maintain_aspect: true,
            fullscreen: false,
            osd_end: Instant::now(),
            stream_info: None,
            rx_subtitle: streams.subtitle,
        })
    }

    /// Add an overlay for the player
    pub fn with_overlay(mut self, overlay: impl PlayerOverlay + 'static) -> Self {
        self.overlay = Box::new(overlay);
        self
    }

    #[allow(unused)]
    fn open_audio(
        state: SharedPlaybackState,
        rx: Receiver<AudioSamples>,
    ) -> Result<Box<dyn AudioDevice>> {
        #[cfg(feature = "audio")]
        return Ok(Box::new(
            crate::audio::AudioDevice::open_default_audio_stream(state, rx)?,
        ));
        Ok(Box::new(NoAudioDevice::new(rx)))
    }

    /// Render player in available space
    pub fn render(&mut self, ui: &mut Ui) -> Response {
        let size = ui.available_size();

        let state = PlaybackInfo {
            state: self.state.state.load(Ordering::Relaxed).into(),
            duration: self.stream_info.as_ref().map(|i| i.duration).unwrap_or(0.0),
            elapsed: (self.state.pts.load(Ordering::Relaxed) as f64 / 1000.0) as _,
            volume: self.state.volume.load(Ordering::Relaxed) as f32 / u16::MAX as f32,
            muted: self.state.mute.load(Ordering::Relaxed),
            playback_speed: self.state.speed.load(Ordering::Relaxed) as f32 / i16::MAX as f32,
            looping: self.media_player.data.looping.load(Ordering::Relaxed),
            fullscreen: self.fullscreen,
            debug: self.debug,
        };
        let upd = self.handle_keys(ui, &state);
        self.process_update(upd);
        self.process_state();
        let frame_response = self.render_frame(ui);
        self.render_subtitles(ui);
        self.render_overlay(ui, &frame_response, &state);
        if let Some(error) = &self.error {
            ui.painter().text(
                pos2(size.x / 2.0, size.y / 2.0),
                Align2::CENTER_BOTTOM,
                error,
                FontId::proportional(30.),
                Color32::DARK_RED,
            );
        }
        if self.osd_end < Instant::now() {
            self.osd.take();
        }
        if let Some(osd) = &self.osd {
            ui.painter().text(
                pos2(size.x - 10.0, 50.0),
                Align2::RIGHT_TOP,
                osd,
                FontId::proportional(20.),
                Color32::WHITE,
            );
        }
        if self.debug {
            self.render_debug(ui, &frame_response, &state);
        }
        frame_response
    }

    fn process_update(&mut self, updates: PlaybackUpdate) {
        // TODO: change internal state
        if updates.any() {
            info!("State change: {:?}", updates);
        }

        if let Some(s) = updates.set_state {
            self.state.store(s as _, Ordering::Relaxed);
            self.show_osd(&s.to_string())
        }
        if let Some(s) = updates.set_volume {
            self.volume.store(s as _, Ordering::Relaxed);
            self.show_osd(&format!("Volume: {}", s));
        }
        if let Some(s) = updates.set_muted {
            self.muted.store(s as _, Ordering::Relaxed);
            self.show_osd(&format!("Muted: {}", s));
        }
        if let Some(s) = updates.set_playback_speed {
            self.playback_speed.store(s as _, Ordering::Relaxed);
            self.show_osd(&format!("Speed: {}", s));
        }
        if let Some(s) = updates.set_seek {
            // TODO: make seeking
            self.show_osd(&format!("Seek: {}", s));
        }
        if let Some(s) = updates.set_looping {
            self.media_player
                .data
                .looping
                .store(s as _, Ordering::Relaxed);
            self.show_osd(&format!("Looping: {}", s));
        }
        if let Some(s) = updates.set_fullscreen {
            self.fullscreen = s;
            // TODO: make fullscreen
            self.show_osd(&format!("Fullscreen: {}", s));
        }
        if let Some(s) = updates.set_debug {
            self.debug = s;
            self.show_osd(&format!("Debug: {}", s));
        }
    }

    fn render_overlay(&mut self, ui: &mut Ui, frame: &Response, state: &PlaybackInfo) {
        let upd = self.overlay.show(ui, frame, state);
        self.process_update(upd);
    }
}

impl Widget for &mut Player {
    fn ui(self, ui: &mut Ui) -> Response {
        self.render(ui)
    }
}
